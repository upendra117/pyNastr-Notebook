{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ALL_DATA\\URGummitha\\Desktop\\Post_Mod-2\\Run_M2.51\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\ALL_DATA\\URGummitha\\Desktop\\Post_Mod-2\\Run_M2.51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============= USER INPUT  ============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING GRID POINT DATA FOR DFEM & GFEM [Created by Hypermesh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfem_nodes_csv_file = 'Fuse_RBE3Nodes.csv'\n",
    "\n",
    "gfem_nodes_csv_file = 'Fuse_RBE3Nodes.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DFEM HDF5 [Input file name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file = './sol101_limit/pc12-47-v1-6-static_post-mod_m2.51_limit.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFEM HDF5 [Input file name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "GFEM_h5_file = 'pc12-47-v1-6-static_post-mod_m3.1_limit.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============== END OF USER INPUT ==============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading HDF5 FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore(h5_file, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfem_store = pd.HDFStore(GFEM_h5_file, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfem_wing_rbe3_nodes = pd.read_csv(dfem_nodes_csv_file)\n",
    "\n",
    "gfem_wing_rbe3_nodes = pd.read_csv(gfem_nodes_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(x, eid_array, cols = list('AB')):\n",
    "    \n",
    "    df = pd.DataFrame(x[:,[0,10]],index=eid_array, columns=cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Join_DF(df1,df2):\n",
    "    \n",
    "    if df1.empty == True:\n",
    "        \n",
    "        df1 = df2.copy()\n",
    "        \n",
    "    else :\n",
    "        \n",
    "        df1 = pd.concat([df1, df2], axis=1, sort=False, join_axes=[df1.index])\n",
    "        \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CBAR_ELEMENTAL_FORCES(store):\n",
    "    \n",
    "    df = store.get('/NASTRAN/RESULT/ELEMENTAL/ELEMENT_FORCE/BAR')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CBEAM_ELEMENTAL_FORCES(store):\n",
    "    \n",
    "    beam_node = store.get_node('/NASTRAN/RESULT/ELEMENTAL/ELEMENT_FORCE/BEAM')\n",
    "\n",
    "    beam_lst_names = beam_node.colnames[1:-1]\n",
    "\n",
    "    res_df = pd.DataFrame({'A' : []})\n",
    "\n",
    "    for x in beam_lst_names:\n",
    "\n",
    "        col_name_a = x + '_A'\n",
    "\n",
    "        col_name_b = x + '_B'\n",
    "\n",
    "        df = get_df(beam_node.col(x), beam_node.col('EID'), cols=[col_name_a, col_name_b])\n",
    "\n",
    "        res_df = Join_DF(res_df, df)\n",
    "        \n",
    "    domain_id_df = pd.DataFrame(beam_node.col('DOMAIN_ID'), index=beam_node.col('EID'), columns=['DOMAIN_ID'])\n",
    "    \n",
    "    res_df = Join_DF(res_df, domain_id_df)\n",
    "    \n",
    "    res_df.index.name = 'EID'\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CELAS2_ELEMENTAL_FORCES(store):\n",
    "    \n",
    "    df = store.get('/NASTRAN/RESULT/ELEMENTAL/ELEMENT_FORCE/ELAS2')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CQUAD4_ELEMENTAL_FORCES(store):\n",
    "    \n",
    "    df = store.get('/NASTRAN/RESULT/ELEMENTAL/ELEMENT_FORCE/QUAD4')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CROD_ELEMENTAL_FORCES(store):\n",
    "    \n",
    "    df = store.get('/NASTRAN/RESULT/ELEMENTAL/ELEMENT_FORCE/ROD')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CBUSH_ELEMENTAL_FORCES(store):\n",
    "    \n",
    "    df = store.get('/NASTRAN/RESULT/ELEMENTAL/ELEMENT_FORCE/BUSH')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSHEAR_ELEMENTAL_FORCES(store):\n",
    "    \n",
    "    df = store.get('/NASTRAN/RESULT/ELEMENTAL/ELEMENT_FORCE/SHEAR')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTRIA3_ELEMENTAL_FORCES(store):\n",
    "    \n",
    "    df = store.get('/NASTRAN/RESULT/ELEMENTAL/ELEMENT_FORCE/TRIA3')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CBAR_ELEMENTAL_STRESS(store):\n",
    "    \n",
    "    df = store.get('/NASTRAN/RESULT/ELEMENTAL/STRESS/BAR')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CBEAM_ELEMENTAL_STRESS(store):\n",
    "    \n",
    "    beam_node = store.get_node('/NASTRAN/RESULT/ELEMENTAL/STRESS/BEAM')\n",
    "\n",
    "    beam_lst_names = beam_node.colnames[1:-1]\n",
    "\n",
    "    res_df = pd.DataFrame({'A' : []})\n",
    "\n",
    "    for x in beam_lst_names:\n",
    "\n",
    "        col_name_a = x + '_A'\n",
    "\n",
    "        col_name_b = x + '_B'\n",
    "\n",
    "        df = get_df(beam_node.col(x), beam_node.col('EID'), cols=[col_name_a, col_name_b])\n",
    "\n",
    "        res_df = Join_DF(res_df, df)\n",
    "        \n",
    "    domain_id_df = pd.DataFrame(beam_node.col('DOMAIN_ID'), index=beam_node.col('EID'), columns=['DOMAIN_ID'])\n",
    "    \n",
    "    res_df.index.name = 'EID'\n",
    "    \n",
    "    res_df = Join_DF(res_df, domain_id_df)\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CELAS2_ELEMENTAL_STRESS(store):\n",
    "    \n",
    "    df = store.get('/NASTRAN/RESULT/ELEMENTAL/STRESS/ELAS2')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CQUAD4_ELEMENTAL_STRESS(store):\n",
    "    \n",
    "    df = store.get('/NASTRAN/RESULT/ELEMENTAL/STRESS/QUAD4')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CROD_ELEMENTAL_STRESS(store):\n",
    "    \n",
    "    df = store.get('/NASTRAN/RESULT/ELEMENTAL/STRESS/ROD')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSHEAR_ELEMENTAL_STRESS(store):\n",
    "    \n",
    "    df = store.get('/NASTRAN/RESULT/ELEMENTAL/STRESS/SHEAR')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTRIA3_ELEMENTAL_STRESS(store):\n",
    "    \n",
    "    df = store.get('/NASTRAN/RESULT/ELEMENTAL/STRESS/TRIA3')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOMAIN_ID Mapping to SUBCASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_results  =  store.get('/NASTRAN/RESULT/DOMAINS')\n",
    "\n",
    "domain_results = domain_results.loc[:, ['ID', 'SUBCASE']].copy()\n",
    "\n",
    "domain_results.set_index('ID', inplace=True)\n",
    "\n",
    "subcase_mapping = domain_results.to_dict()\n",
    "\n",
    "# subcase_mapping['SUBCASE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID POINT EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_NODAL_DISPLACEMENT(store):\n",
    "    \n",
    "    df = store.get('/NASTRAN/RESULT/NODAL/DISPLACEMENT')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gp_dispacements = GP_NODAL_DISPLACEMENT(store)\n",
    "\n",
    "# gp_dispacements.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom function to extract grid point forces for selected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Custom_GP_Forces(all_gp_df, wing_gp_nodes_df ):\n",
    "\n",
    "    filter_bool = all_gp_df.ID.isin(wing_gp_nodes_df.dependentnode.tolist())\n",
    "\n",
    "    gp_dispacements = all_gp_df[filter_bool == True].copy()\n",
    "\n",
    "    # gp_dispacements.head()\n",
    "\n",
    "    gp_dispacements['SUBCASE'] = gp_dispacements.DOMAIN_ID.map(subcase_mapping['SUBCASE']).copy()\n",
    "\n",
    "    # gp_dispacements.head()\n",
    "\n",
    "    take_slice = wing_gp_nodes_df[['dependentnode', 'globalx', 'globaly', 'globalz']].copy()\n",
    "\n",
    "    take_slice.columns = ['ID', 'X_Cord', 'Y_Cord', 'Z_Cord']\n",
    "\n",
    "    # take_slice.head()\n",
    "\n",
    "    merged_df  = gp_dispacements.merge(take_slice, on=['ID'], how='outer')\n",
    "\n",
    "    # merged_df.head()\n",
    "\n",
    "    merged_df.columns = ['DEPENDENT_NODE', 'X', 'Y', 'Z', 'RX', 'RY', 'RZ', 'DOMAIN_ID', 'SUBCASE', 'X_Cord',\n",
    "           'Y_Cord', 'Z_Cord']\n",
    "\n",
    "    # merged_df.head()\n",
    "\n",
    "    merged_df['Rx_in_Degree'] = merged_df.RX * (180.0/np.pi)\n",
    "\n",
    "    merged_df['Ry_in_Degree'] = merged_df.RY * (180.0/np.pi)\n",
    "\n",
    "    merged_df['Rz_in_Degree'] = merged_df.RZ * (180.0/np.pi)\n",
    "    \n",
    "    # merged_df.to_csv('DFEM_wing_displacements.csv')\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Custom_Switch_X_to_Y(df):\n",
    "    \n",
    "    new_column_order = ['DEPENDENT_NODE', 'X', 'Y', 'Z', 'RX', 'RY', 'RZ', 'DOMAIN_ID',\n",
    "       'SUBCASE', 'Y_Cord', 'X_Cord', 'Z_Cord', 'Rx_in_Degree', 'Ry_in_Degree',\n",
    "       'Rz_in_Degree']\n",
    "    \n",
    "    df = df.reindex(columns=new_column_order).copy()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfem_wing_rbe3_nodes = dfem_wing_rbe3_nodes[(dfem_wing_rbe3_nodes[['globalx', 'globaly', 'globalz']] != 0).all(axis=1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfem_wing_rbe3_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfem_extraction_df = Custom_GP_Forces(all_gp_dispacements, dfem_wing_rbe3_nodes)\n",
    "\n",
    "dfem_extraction_df = Custom_Switch_X_to_Y(dfem_extraction_df)\n",
    "\n",
    "# dfem_extraction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'a':np.random.randn(3), 'b': np.random.randn(3), 'c':np.random.randn(3)})\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.reindex(columns=['c','a','b'])\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gfem_gp_displacemnts = GP_NODAL_DISPLACEMENT(gfem_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfem_extraction_df = Custom_GP_Forces(all_gfem_gp_displacemnts, gfem_wing_rbe3_nodes)\n",
    "\n",
    "gfem_extraction_df = Custom_Switch_X_to_Y(gfem_extraction_df)\n",
    "\n",
    "# gfem_extraction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('FUSE_NODE_DISPLACEMENT_EXTRACTION.xlsx') as writer:\n",
    "    \n",
    "    dfem_extraction_df.to_excel(writer, sheet_name='DFEM_EXTRACTION')\n",
    "    \n",
    "    gfem_extraction_df.to_excel(writer, sheet_name='GFEM_EXTRACTION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = dfem_extraction_df.merge(gfem_extraction_df, on=['DEPENDENT_NODE'], suffixes=('_DFEM', '_GFEM'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('FUSE_NODE_DISPLACEMENT_EXTRACTION_COMBINED.xlsx') as writer:\n",
    "    \n",
    "    merged_df.to_excel(writer, sheet_name='COMBINED_DGFEM_EXTRACTION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close the Entire Store HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing the dfem store\n",
    "store.close()\n",
    "\n",
    "# closing the gfem store\n",
    "gfem_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF PYTHON RUN.\n"
     ]
    }
   ],
   "source": [
    "print('END OF PYTHON RUN.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
